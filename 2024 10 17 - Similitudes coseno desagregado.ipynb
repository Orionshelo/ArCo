{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350e92c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_11540\\2977026901.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df[columns].applymap(lambda x: 1 if x in [\"Si\", np.nan] else 0)\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_11540\\2977026901.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df[columns].applymap(lambda x: 1 if x in [\"Si\", np.nan] else 0)\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_11540\\2977026901.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df[columns].applymap(lambda x: 1 if x in [\"Si\", np.nan] else 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"C:/Backup - Archivos de trabajo/DNP/Automatización ArCo/Excel\")\n",
    "\n",
    "# Import data\n",
    "data = pd.read_excel(\"2024 10 16 - Base Original.xlsx\")\n",
    "\n",
    "# Prepare data\n",
    "def prepare_data(df, columns):\n",
    "    return df[columns].applymap(lambda x: 1 if x in [\"Si\", np.nan] else 0)\n",
    "\n",
    "tip_usu = prepare_data(data, [\"Emprendedores\", \"Mipymes\", \"Grandes empresas\", \"Gobierno \", \"Academia\", \"Entidades de soporte\", \"Personas naturales\"])\n",
    "tip_apoyo = prepare_data(data, [\"Formación de Talento Humano\", \"Tipo de Sistemas de Información\", \"Asistencia técnica y Consultoría\", \"Tipo de Redes de Colaboración\", \"Apoyo Financiero\", \"Incentivos Tributarios\", \"Eventos\", \"Compra Pública\", \"Bonos o Vouchers\", \"Premios y Reconocimientos\", \"Instrumentos Regulatorios\"])\n",
    "ob_oferta = prepare_data(data, [\"Innovación\", \"Emprendimiento\", \"Economía Popular\", \"Transferencia de Conocimiento y Tecnología\", \"Investigación\", \"Formación de Capital Humano\", \"Propiedad intelectual\", \"Calidad\", \"Clúster o encadenamientos\", \"Financiación\", \"Comercialización\", \"Formalización\", \"Crecimiento Sostenible\", \"Inclusión Financiera\", \"Comercio Electrónico\", \"Educación económica y financiera\", \"Competencias Digitales\"])\n",
    "\n",
    "# Custom cosine similarity function\n",
    "def custom_cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    magnitude_a = np.linalg.norm(a)\n",
    "    magnitude_b = np.linalg.norm(b)\n",
    "    \n",
    "    if magnitude_a == 0 or magnitude_b == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dot_product / (magnitude_a * magnitude_b)\n",
    "\n",
    "# Function to calculate detailed cosine similarity\n",
    "def calculate_detailed_cosine_similarity(df):\n",
    "    n, m = df.shape\n",
    "    result = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                cosine_sim = custom_cosine_similarity(df.iloc[i], df.iloc[j]) * 100\n",
    "                element_sim = (df.iloc[i] == df.iloc[j]) * 100\n",
    "                \n",
    "                result.append({\n",
    "                    \"Instrumento1\": data[\"Nombre del Instrumento\"].iloc[i],\n",
    "                    \"Instrumento2\": data[\"Nombre del Instrumento\"].iloc[j],\n",
    "                    \"Similitud_Coseno\": cosine_sim,\n",
    "                    **{col: sim for col, sim in zip(df.columns, element_sim)}\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "# Calculate detailed cosine similarities\n",
    "sim_usu = calculate_detailed_cosine_similarity(tip_usu)\n",
    "sim_apoyo = calculate_detailed_cosine_similarity(tip_apoyo)\n",
    "sim_oferta = calculate_detailed_cosine_similarity(ob_oferta)\n",
    "\n",
    "# Function to export to Excel\n",
    "def export_to_excel(df, filename):\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='Similitud', index=False)\n",
    "\n",
    "# Export results\n",
    "export_to_excel(sim_usu, \"Similitud_coseno_desagregada_usuarios_1.xlsx\")\n",
    "export_to_excel(sim_apoyo, \"Similitud_coseno_desagregada_apoyo_1.xlsx\")\n",
    "export_to_excel(sim_oferta, \"Similitud_coseno_desagregada_oferta_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "386f455f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Ejecutar el análisis\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m articulation_results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_articulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Exportar resultados\u001b[39;00m\n\u001b[0;32m    117\u001b[0m articulation_results\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalisis_Articulacion_Instrumentos_Detallado.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[12], line 71\u001b[0m, in \u001b[0;36manalyze_articulation\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, other_row \u001b[38;5;129;01min\u001b[39;00m prepared_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m     69\u001b[0m         sim \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSUARIOS\u001b[39m\u001b[38;5;124m'\u001b[39m: calculate_similarity(row[usuarios_cols], other_row[usuarios_cols]),\n\u001b[1;32m---> 71\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOBJETIVO\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobjetivo_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_row\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobjetivo_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPOYO\u001b[39m\u001b[38;5;124m'\u001b[39m: calculate_similarity(row[apoyo_cols], other_row[apoyo_cols]),\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENTIDAD\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntidad\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntidad\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     74\u001b[0m         }\n\u001b[0;32m     75\u001b[0m         sim[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOTAL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mlist\u001b[39m(sim\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m     76\u001b[0m         sim[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m j\n",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m, in \u001b[0;36mcalculate_similarity\u001b[1;34m(row1, row2)\u001b[0m\n\u001b[0;32m     17\u001b[0m set2 \u001b[38;5;241m=\u001b[39m row2\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calcular intersección y unión\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m intersection \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     21\u001b[0m union \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_or(set1, set2)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Evitar división por cero\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2102\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2098\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2100\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   2101\u001b[0m ):\n\u001b[1;32m-> 2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:321\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m             axes[i] \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39munion(ax2)\n\u001b[0;32m    320\u001b[0m     reconstruct_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS, axes))\n\u001b[1;32m--> 321\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    322\u001b[0m         x\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreconstruct_axes) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, NDFrame) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, types)\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     reconstruct_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes))\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:322\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    318\u001b[0m             axes[i] \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39munion(ax2)\n\u001b[0;32m    320\u001b[0m     reconstruct_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS, axes))\n\u001b[0;32m    321\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m--> 322\u001b[0m         \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreconstruct_axes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, NDFrame) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, types)\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     reconstruct_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes))\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4977\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4960\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   4961\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   4962\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4975\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4976\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 4977\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5514\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5508\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   5509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m   5510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis_name)\u001b[38;5;241m.\u001b[39midentical(ax)\n\u001b[0;32m   5511\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis_name, ax \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   5512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   5513\u001b[0m ):\n\u001b[1;32m-> 5514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5516\u001b[0m \u001b[38;5;66;03m# check if we are a multi reindex\u001b[39;00m\n\u001b[0;32m   5517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_reindex_multi(axes, method, level):\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6685\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6553\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6555\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6556\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6557\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6683\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6685\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6688\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6689\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:576\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 576\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:645\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    643\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 645\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    646\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Establecer el directorio de trabajo\n",
    "os.chdir(\"C:/Backup - Archivos de trabajo/DNP/Automatización ArCo/Excel\")\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_excel(\"2024 10 17 - Base Original.xlsx\")\n",
    "\n",
    "def prepare_data(df, columns):\n",
    "    return df[columns].replace({\"Si\": 1, \"No\": 0}).fillna(0)\n",
    "\n",
    "def calculate_similarity(row1, row2):\n",
    "    # Convertir a arrays booleanos para facilitar operaciones de conjuntos\n",
    "    set1 = row1.astype(bool)\n",
    "    set2 = row2.astype(bool)\n",
    "    \n",
    "    # Calcular intersección y unión\n",
    "    intersection = np.logical_and(set1, set2).sum()\n",
    "    union = np.logical_or(set1, set2).sum()\n",
    "    \n",
    "    # Evitar división por cero\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calcular índice de Jaccard y convertir a porcentaje\n",
    "    return (intersection / union) * 100\n",
    "\n",
    "def categorize_similarity(value, thresholds):\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if value <= threshold:\n",
    "            return i\n",
    "    return len(thresholds)\n",
    "\n",
    "def analyze_articulation(data):\n",
    "    results = []\n",
    "    \n",
    "    usuarios_cols = ['Emprendedores', 'Mipymes', 'Grandes empresas', 'Gobierno ', 'Academia', 'Entidades de soporte', 'Personas naturales']\n",
    "    objetivo_cols = ['Innovación', 'Emprendimiento', 'Economía Popular', 'Transferencia de Conocimiento y Tecnología', 'Investigación', 'Formación de Capital Humano', 'Propiedad intelectual', 'Calidad', 'Clúster o encadenamientos', 'Financiación', 'Comercialización', 'Formalización', 'Crecimiento Sostenible', 'Inclusión Financiera', 'Comercio Electrónico', 'Educación económica y financiera', 'Competencias Digitales']\n",
    "    apoyo_cols = ['Formación de Talento Humano', 'Tipo de Sistemas de Información', 'Asistencia técnica y Consultoría', 'Tipo de Redes de Colaboración', 'Apoyo Financiero', 'Incentivos Tributarios', 'Eventos', 'Compra Pública', 'Bonos o Vouchers', 'Premios y Reconocimientos', 'Instrumentos Regulatorios']\n",
    "    \n",
    "    prepared_data = prepare_data(data, usuarios_cols + objetivo_cols + apoyo_cols)\n",
    "    \n",
    "    all_similarities = {\n",
    "        'USUARIOS': [],\n",
    "        'OBJETIVO': [],\n",
    "        'APOYO': [],\n",
    "        'ENTIDAD': []\n",
    "    }\n",
    "    \n",
    "    # Calcular todas las similitudes primero para establecer los umbrales\n",
    "    for i, row in prepared_data.iterrows():\n",
    "        for j, other_row in prepared_data.iterrows():\n",
    "            if i != j:\n",
    "                all_similarities['USUARIOS'].append(calculate_similarity(row[usuarios_cols], other_row[usuarios_cols]))\n",
    "                all_similarities['OBJETIVO'].append(calculate_similarity(row[objetivo_cols], other_row[objetivo_cols]))\n",
    "                all_similarities['APOYO'].append(calculate_similarity(row[apoyo_cols], other_row[apoyo_cols]))\n",
    "                all_similarities['ENTIDAD'].append(100 if data.loc[i, 'Entidad'] == data.loc[j, 'Entidad'] else 0)\n",
    "    \n",
    "    thresholds = {k: np.percentile(v, [25, 50, 75]) for k, v in all_similarities.items()}\n",
    "    \n",
    "    # Analizar cada instrumento\n",
    "    for i, row in prepared_data.iterrows():\n",
    "        similarities = []\n",
    "        \n",
    "        for j, other_row in prepared_data.iterrows():\n",
    "            if i != j:\n",
    "                sim = {\n",
    "                    'USUARIOS': calculate_similarity(row[usuarios_cols], other_row[usuarios_cols]),\n",
    "                    'OBJETIVO': calculate_similarity(row[objetivo_cols], other_row[objetivo_cols]),\n",
    "                    'APOYO': calculate_similarity(row[apoyo_cols], other_row[apoyo_cols]),\n",
    "                    'ENTIDAD': 100 if data.loc[i, 'Entidad'] == data.loc[j, 'Entidad'] else 0\n",
    "                }\n",
    "                sim['TOTAL'] = np.mean(list(sim.values()))\n",
    "                sim['index'] = j\n",
    "                similarities.append(sim)\n",
    "        \n",
    "        similarities.sort(key=lambda x: x['TOTAL'], reverse=True)\n",
    "        best_match = similarities[0]\n",
    "        \n",
    "        avg_similarities = {k: best_match[k] for k in ['USUARIOS', 'OBJETIVO', 'APOYO', 'ENTIDAD']}\n",
    "        similarity_categories = {k: categorize_similarity(v, thresholds[k]) for k, v in avg_similarities.items()}\n",
    "        \n",
    "        # Determinar nivel de articulación\n",
    "        if all(cat == 3 for cat in similarity_categories.values()):\n",
    "            articulation_level = \"2. Fusionar\"\n",
    "        elif similarity_categories['USUARIOS'] >= 2 and similarity_categories['OBJETIVO'] >= 2 and similarity_categories['APOYO'] >= 2:\n",
    "            articulation_level = \"3. Definir roles\"\n",
    "        elif similarity_categories['USUARIOS'] >= 2 and similarity_categories['OBJETIVO'] >= 2:\n",
    "            articulation_level = \"4. Empaquetar\"\n",
    "        elif similarity_categories['USUARIOS'] >= 2:\n",
    "            articulation_level = \"5. Generar rutas\"\n",
    "        else:\n",
    "            articulation_level = \"1. Renunciar\"\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results.append({\n",
    "            'Instrumento1': data.loc[i, 'Nombre del Instrumento'],\n",
    "            'Descripción1': data.loc[i, 'Descripción'],\n",
    "            'Entidad1': data.loc[i, 'Entidad'],\n",
    "            'Instrumento2': data.loc[best_match['index'], 'Nombre del Instrumento'],\n",
    "            'Descripción2': data.loc[best_match['index'], 'Descripción'],\n",
    "            'Entidad2': data.loc[best_match['index'], 'Entidad'],\n",
    "            'Nivel de Articulación': articulation_level,\n",
    "            'Similitud Total': best_match['TOTAL'],\n",
    "            **avg_similarities,\n",
    "            **{f\"{k}_Categoría\": v for k, v in similarity_categories.items()}\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar el análisis\n",
    "articulation_results = analyze_articulation(data)\n",
    "\n",
    "# Exportar resultados\n",
    "articulation_results.to_excel(\"Analisis_Articulacion_Instrumentos_Detallado.xlsx\", index=False)\n",
    "\n",
    "print(\"Análisis completado. Los resultados se han guardado en 'Analisis_Articulacion_Instrumentos_Detallado.xlsx'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4788f6",
   "metadata": {},
   "source": [
    "## Con distancia de Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5718eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis completado. Los resultados se han guardado en 'Analisis_Articulacion_Instrumentos_Detallado.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Establecer el directorio de trabajo\n",
    "os.chdir(\"C:/Backup - Archivos de trabajo/DNP/Automatización ArCo/Excel\")\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_excel(\"2024 10 17 - Base Original.xlsx\")\n",
    "\n",
    "def prepare_data(df, columns):\n",
    "    return df[columns].replace({\"Si\": 1, \"No\": 0}).fillna(0).values\n",
    "\n",
    "def calculate_similarity_matrix(matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calcula la matriz de similitud usando operaciones vectorizadas.\n",
    "    Retorna porcentajes de similitud (100 - distancia_hamming).\n",
    "    \"\"\"\n",
    "    # Calcula la distancia de Hamming normalizada entre todas las filas\n",
    "    distances = cdist(matrix1, matrix2, metric='hamming')\n",
    "    # Convierte distancias a similitudes (en porcentaje)\n",
    "    return (1 - distances) * 100\n",
    "\n",
    "def analyze_articulation(data):\n",
    "    # Definir columnas para cada categoría\n",
    "    usuarios_cols = ['Emprendedores', 'Mipymes', 'Grandes empresas', 'Gobierno ', 'Academia', 'Entidades de soporte', 'Personas naturales']\n",
    "    objetivo_cols = ['Innovación', 'Emprendimiento', 'Economía Popular', 'Transferencia de Conocimiento y Tecnología', 'Investigación', 'Formación de Capital Humano', 'Propiedad intelectual', 'Calidad', 'Clúster o encadenamientos', 'Financiación', 'Comercialización', 'Formalización', 'Crecimiento Sostenible', 'Inclusión Financiera', 'Comercio Electrónico', 'Educación económica y financiera', 'Competencias Digitales']\n",
    "    apoyo_cols = ['Formación de Talento Humano', 'Tipo de Sistemas de Información', 'Asistencia técnica y Consultoría', 'Tipo de Redes de Colaboración', 'Apoyo Financiero', 'Incentivos Tributarios', 'Eventos', 'Compra Pública', 'Bonos o Vouchers', 'Premios y Reconocimientos', 'Instrumentos Regulatorios']\n",
    "    \n",
    "    # Preparar matrices binarias\n",
    "    usuarios_matrix = prepare_data(data, usuarios_cols)\n",
    "    objetivo_matrix = prepare_data(data, objetivo_cols)\n",
    "    apoyo_matrix = prepare_data(data, apoyo_cols)\n",
    "    \n",
    "    # Calcular matrices de similitud para cada categoría\n",
    "    usuarios_sim = calculate_similarity_matrix(usuarios_matrix, usuarios_matrix)\n",
    "    objetivo_sim = calculate_similarity_matrix(objetivo_matrix, objetivo_matrix)\n",
    "    apoyo_sim = calculate_similarity_matrix(apoyo_matrix, apoyo_matrix)\n",
    "    \n",
    "    # Crear matriz de similitud para entidades\n",
    "    n = len(data)\n",
    "    entidad_sim = np.zeros((n, n))\n",
    "    entidades = data['Entidad'].values\n",
    "    entidad_sim = np.equal.outer(entidades, entidades).astype(float) * 100\n",
    "    \n",
    "    # Calcular umbrales para cada categoría\n",
    "    def calculate_thresholds(sim_matrix):\n",
    "        # Obtener valores superiores de la matriz triangular (excluyendo la diagonal)\n",
    "        upper_tri = sim_matrix[np.triu_indices(n, k=1)]\n",
    "        return np.percentile(upper_tri, [25, 50, 75])\n",
    "    \n",
    "    thresholds = {\n",
    "        'USUARIOS': calculate_thresholds(usuarios_sim),\n",
    "        'OBJETIVO': calculate_thresholds(objetivo_sim),\n",
    "        'APOYO': calculate_thresholds(apoyo_sim),\n",
    "        'ENTIDAD': calculate_thresholds(entidad_sim)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Analizar cada instrumento\n",
    "    for i in range(n):\n",
    "        # Calcular similitud total promedio con todos los demás instrumentos\n",
    "        total_sim = (usuarios_sim[i] + objetivo_sim[i] + apoyo_sim[i] + entidad_sim[i]) / 4\n",
    "        total_sim[i] = -1  # Excluir comparación consigo mismo\n",
    "        \n",
    "        # Encontrar el mejor match\n",
    "        best_match_idx = np.argmax(total_sim)\n",
    "        \n",
    "        # Obtener similitudes individuales con el mejor match\n",
    "        similarities = {\n",
    "            'USUARIOS': usuarios_sim[i, best_match_idx],\n",
    "            'OBJETIVO': objetivo_sim[i, best_match_idx],\n",
    "            'APOYO': apoyo_sim[i, best_match_idx],\n",
    "            'ENTIDAD': entidad_sim[i, best_match_idx]\n",
    "        }\n",
    "        \n",
    "        # Categorizar similitudes\n",
    "        similarity_categories = {\n",
    "            k: sum(v > threshold for threshold in thresholds[k])\n",
    "            for k, v in similarities.items()\n",
    "        }\n",
    "        \n",
    "        # Determinar nivel de articulación\n",
    "        if all(cat == 3 for cat in similarity_categories.values()):\n",
    "            articulation_level = \"2. Fusionar\"\n",
    "        elif similarity_categories['USUARIOS'] >= 2 and similarity_categories['OBJETIVO'] >= 2 and similarity_categories['APOYO'] >= 2:\n",
    "            articulation_level = \"3. Definir roles\"\n",
    "        elif similarity_categories['USUARIOS'] >= 2 and similarity_categories['OBJETIVO'] >= 2:\n",
    "            articulation_level = \"4. Empaquetar\"\n",
    "        elif similarity_categories['USUARIOS'] >= 2:\n",
    "            articulation_level = \"5. Generar rutas\"\n",
    "        else:\n",
    "            articulation_level = \"1. Renunciar\"\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results.append({\n",
    "            'Instrumento1': data.iloc[i]['Nombre del Instrumento'],\n",
    "            'Descripción1': data.iloc[i]['Descripción'],\n",
    "            'Entidad1': data.iloc[i]['Entidad'],\n",
    "            'Instrumento2': data.iloc[best_match_idx]['Nombre del Instrumento'],\n",
    "            'Descripción2': data.iloc[best_match_idx]['Descripción'],\n",
    "            'Entidad2': data.iloc[best_match_idx]['Entidad'],\n",
    "            'Nivel de Articulación': articulation_level,\n",
    "            'Similitud Total': total_sim[best_match_idx],\n",
    "            **similarities,\n",
    "            **{f\"{k}_Categoría\": v for k, v in similarity_categories.items()}\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar el análisis\n",
    "articulation_results = analyze_articulation(data)\n",
    "\n",
    "# Exportar resultados\n",
    "articulation_results.to_excel(\"Analisis_Articulacion_Instrumentos_Detallado.xlsx\", index=False)\n",
    "\n",
    "print(\"Análisis completado. Los resultados se han guardado en 'Analisis_Articulacion_Instrumentos_Detallado.xlsx'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
