{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "###### ArCo ARMADO DE LA BASE#######\n",
    "import os\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "# Establecer el directorio de trabajo\n",
    "os.chdir(\"C:/Users/supegui/Documents/Metodología ArCo/Python/Excel\")\n",
    "# Saca la lista de archivos del directorio de trabajo\n",
    "#os.listdir()\n",
    "# Obtener la fecha actual\n",
    "fecha_actual = datetime.now().strftime(\"%Y %m %d\")\n",
    "#print(fecha_actual)\n",
    "\n",
    "# Construir el nombre del archivo basado en la fecha actual\n",
    "#nombre_archivo = f\"{fecha_actual} Informe ArCo.xlsx\"\n",
    "\n",
    "# Construir el nombre del archivo cuando la fecha no es la actual. Aquí solo se modifica la fecha. \n",
    "nombre_archivo = \"2024 11 01 - Base Original.xlsx\"\n",
    "\n",
    "data_arco = pd.read_excel(nombre_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Primero, creamos una matriz de características binarias para cada instrumento\n",
    "def crear_matriz_caracteristicas(data_arco):\n",
    "    # Seleccionamos las columnas relevantes\n",
    "    cols_usuarios = ['Emprendedores', 'Mipymes', 'Grandes empresas', 'Gobierno ', 'Academia', 'Entidades de soporte', 'Personas naturales']\n",
    "    \n",
    "    # Creamos una matriz donde cada fila es un instrumento y cada columna es un tipo de usuario\n",
    "    matriz_caracteristicas = data_arco[cols_usuarios].copy()\n",
    "    \n",
    "    # Convertimos 'Si'/'No' a 1/0\n",
    "    matriz_caracteristicas = (matriz_caracteristicas == 'Si').astype(int)\n",
    "    \n",
    "    return matriz_caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Emprendedores  Mipymes  Grandes empresas  Gobierno   Academia  \\\n",
      "0                0        0                 0          0         0   \n",
      "1                0        0                 1          0         0   \n",
      "2                0        1                 1          1         1   \n",
      "3                0        0                 0          1         0   \n",
      "4                0        0                 0          1         1   \n",
      "..             ...      ...               ...        ...       ...   \n",
      "414              0        0                 0          0         0   \n",
      "415              0        1                 0          1         1   \n",
      "416              0        1                 0          1         1   \n",
      "417              0        0                 0          0         0   \n",
      "418              1        1                 1          1         0   \n",
      "\n",
      "     Entidades de soporte  Personas naturales  \n",
      "0                       1                   0  \n",
      "1                       1                   0  \n",
      "2                       1                   1  \n",
      "3                       0                   0  \n",
      "4                       1                   1  \n",
      "..                    ...                 ...  \n",
      "414                     0                   1  \n",
      "415                     1                   1  \n",
      "416                     1                   1  \n",
      "417                     0                   1  \n",
      "418                     1                   1  \n",
      "\n",
      "[419 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "matriz_cara = crear_matriz_caracteristicas(data_arco)\n",
    "\n",
    "print(matriz_cara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# 2. Calculamos la similitud entre instrumentos - Jaccard\n",
    "def calcular_similitud(data_arco):\n",
    "    # Obtenemos la matriz de características\n",
    "    matriz = crear_matriz_caracteristicas(data_arco)\n",
    "    \n",
    "    # Inicializamos la matriz de similitud\n",
    "    n_instrumentos = len(data_arco)\n",
    "    matriz_similitud = np.zeros((n_instrumentos, n_instrumentos))\n",
    "    \n",
    "    # Calculamos la similitud para cada par de instrumentos\n",
    "    for i in range(n_instrumentos):\n",
    "        for j in range(n_instrumentos):\n",
    "            # Extraemos los vectores de características para los instrumentos i y j\n",
    "            instrumento_i = matriz.iloc[i].values\n",
    "            instrumento_j = matriz.iloc[j].values\n",
    "            \n",
    "            # Calculamos similitud usando coincidencias\n",
    "            coincidencias = sum(instrumento_i & instrumento_j)  # AND lógico\n",
    "            total_usuarios = sum(instrumento_i | instrumento_j)  # OR lógico\n",
    "            \n",
    "            # Calculamos el coeficiente de Jaccard\n",
    "            if total_usuarios > 0:\n",
    "                similitud = coincidencias / total_usuarios\n",
    "            else:\n",
    "                similitud = 0\n",
    "                \n",
    "            matriz_similitud[i][j] = similitud\n",
    "    \n",
    "    return matriz_similitud\n",
    "\"\"\"\"2024 10 25 - Base Original.xlsx\"\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def calcular_similitud(data_arco):\n",
    "    # Obtenemos la matriz de características\n",
    "    matriz = crear_matriz_caracteristicas(data_arco)\n",
    "    \n",
    "    # Calculamos la matriz de similitud de coseno\n",
    "    matriz_similitud = cosine_similarity(matriz)\n",
    "    \n",
    "    return matriz_similitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Convertimos la similitud a ratings\n",
    "def calcular_ratings(data_arco):\n",
    "    # Calculamos la matriz de similitud\n",
    "    matriz_similitud = calcular_similitud(data_arco)\n",
    "    \n",
    "    # Creamos un DataFrame con los ratings\n",
    "    ratings = []\n",
    "    \n",
    "    for i in range(len(matriz_similitud)):\n",
    "        for j in range(len(matriz_similitud)):\n",
    "            if i != j:  # No incluimos la similitud de un instrumento consigo mismo\n",
    "                ratings.append({\n",
    "                    'Instrumento_A': data_arco.iloc[i]['Código'],\n",
    "                    'Nombre_A': data_arco.iloc[i]['Nombre del Instrumento'],\n",
    "                    'Instrumento_B': data_arco.iloc[j]['Código'],\n",
    "                    'Nombre_B': data_arco.iloc[j]['Nombre del Instrumento'],\n",
    "                    'Rating': round(matriz_similitud[i][j] * 5, 2)  # Convertimos a escala 0-5\n",
    "                })\n",
    "    \n",
    "    df_ratings = pd.DataFrame(ratings)\n",
    "    \n",
    "    # Ordenamos por rating de mayor a menor\n",
    "    df_ratings = df_ratings.sort_values('Rating', ascending=False)\n",
    "    \n",
    "    return df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Instrumento_A                                           Nombre_A  \\\n",
      "132990           2853                      Programa Incentivo a medallas   \n",
      "129027           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "128984           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "128986           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "128991           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "128992           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "128994           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "128997           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "162672           3631  Acompañamiento para la territorialización de l...   \n",
      "129007           2832  Beneficio de Estímulo Económico de Sometimient...   \n",
      "\n",
      "        Instrumento_B                                           Nombre_B  \\\n",
      "132990            552  Servicio de adjudicación de bienes fiscales pa...   \n",
      "129027           2770  Mejoramiento de Acceso a la Justicia Local y R...   \n",
      "128984           2388  Programa de Fortalecimiento Productivo y Comer...   \n",
      "128986           2392                                  Talentos Colombia   \n",
      "128991           2414                       Economía popular comunitaria   \n",
      "128992           2415                                  Colombia Programa   \n",
      "128994           2420                                        Jover Rural   \n",
      "128997           2428  Línea Especial de Microcrédito Inclusión Finan...   \n",
      "162672            556  Herramienta para la valoración del riesgo y la...   \n",
      "129007           2448                                        Mujer Rural   \n",
      "\n",
      "        Rating  \n",
      "132990     5.0  \n",
      "129027     5.0  \n",
      "128984     5.0  \n",
      "128986     5.0  \n",
      "128991     5.0  \n",
      "128992     5.0  \n",
      "128994     5.0  \n",
      "128997     5.0  \n",
      "162672     5.0  \n",
      "129007     5.0  \n"
     ]
    }
   ],
   "source": [
    "# 4. Función principal que integra todo el proceso\n",
    "def generar_ratings_colaborativos(data_arco):\n",
    "    # Calculamos los ratings\n",
    "    df_ratings = calcular_ratings(data_arco)\n",
    "    \n",
    "    # Filtramos solo los pares con rating significativo (por ejemplo, mayor a 2)\n",
    "    df_ratings_significativos = df_ratings[df_ratings['Rating'] > 2]\n",
    "    \n",
    "    return df_ratings_significativos\n",
    "\n",
    "# Ejemplo de uso:\n",
    "ratings_finales = generar_ratings_colaborativos(data_arco)\n",
    "print(ratings_finales.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de recomendación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    # Crear y evaluar el sistema\\n    sistema = crear_y_evaluar_sistema(ratings_finales)\\n    \\n    # Generar recomendaciones para un instrumento específico\\n    instrumento_ejemplo = ratings_finales[\\'Instrumento_A\\'].iloc[126]\\n    recomendaciones = sistema.generar_recomendaciones(instrumento_ejemplo, n=20)\\n    print(\"\\nRecomendaciones para instrumento\", instrumento_ejemplo)\\n    print(recomendaciones)\\n    \\nexcept Exception as e:\\n    print(f\"Error: {str(e)}\")\\n    \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD, KNNBasic, NMF, accuracy, similarities\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from collections import defaultdict\n",
    "\n",
    "class SistemaRecomendacion:\n",
    "    def __init__(self, df_ratings):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema de recomendación con el DataFrame de ratings\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df_ratings : pandas.DataFrame\n",
    "            DataFrame que debe contener las columnas ['Instrumento_A', 'Instrumento_B', 'Rating']\n",
    "        \"\"\"\n",
    "        # Validar que el DataFrame tiene las columnas necesarias\n",
    "        required_columns = ['Instrumento_A', 'Instrumento_B', 'Rating']\n",
    "        if not all(col in ratings_finales.columns for col in required_columns):\n",
    "            raise ValueError(f\"El DataFrame debe contener las columnas: {required_columns}\")\n",
    "            \n",
    "        self.ratings_finales = ratings_finales.copy()\n",
    "        \n",
    "        # Verificar que no hay valores nulos\n",
    "        if self.ratings_finales[required_columns].isna().any().any():\n",
    "            raise ValueError(\"El DataFrame contiene valores nulos\")\n",
    "        \n",
    "        # Aseguramos que los ratings están en el rango correcto\n",
    "        self.ratings_finales['Rating'] = self.ratings_finales['Rating'].clip(0, 5)\n",
    "        \n",
    "        # Configuramos el reader con un rango válido\n",
    "        self.reader = Reader(rating_scale=(0, 5))\n",
    "        \n",
    "        try:\n",
    "            # Convertimos a formato Surprise\n",
    "            self.data = Dataset.load_from_df(\n",
    "                self.ratings_finales[required_columns], \n",
    "                self.reader\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error al convertir datos al formato Surprise: {str(e)}\")\n",
    "        \n",
    "        # Definimos los modelos base\n",
    "        self.modelos = {\n",
    "            'SVD': SVD(\n",
    "                n_factors=50,\n",
    "                n_epochs=20,\n",
    "                lr_all=0.005,\n",
    "                reg_all=0.02,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'NMF': NMF(\n",
    "                n_factors=15,\n",
    "                n_epochs=50,\n",
    "                random_state=42\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Calcular el número de ratings por instrumento de manera correcta\n",
    "        ratings_a = self.ratings_finales['Instrumento_A'].value_counts()\n",
    "        ratings_b = self.ratings_finales['Instrumento_B'].value_counts()\n",
    "        \n",
    "        # Combinar los conteos\n",
    "        todos_instrumentos = set(ratings_a.index) | set(ratings_b.index)\n",
    "        ratings_totales = pd.Series(0, index=todos_instrumentos)\n",
    "        \n",
    "        for instrumento in todos_instrumentos:\n",
    "            total = (ratings_a.get(instrumento, 0) + \n",
    "                    ratings_b.get(instrumento, 0))\n",
    "            ratings_totales[instrumento] = total\n",
    "        \n",
    "        min_ratings = ratings_totales.min()\n",
    "        print(f\"Número mínimo de ratings por instrumento: {min_ratings}\")\n",
    "        print(f\"Número máximo de ratings por instrumento: {ratings_totales.max()}\")\n",
    "        print(f\"Promedio de ratings por instrumento: {ratings_totales.mean():.2f}\")\n",
    "        \n",
    "        # Agregamos KNN solo si tenemos suficientes datos y ratings\n",
    "        if len(self.ratings_finales) > 10 and min_ratings >= 2:\n",
    "            # Calculamos k de manera más conservadora\n",
    "            k = min(\n",
    "                20,  # máximo valor de k\n",
    "                max(2, len(self.ratings_finales) // 10)  # k proporcional al tamaño del dataset\n",
    "            )\n",
    "            \n",
    "            self.modelos['KNN'] = KNNBasic(\n",
    "                k=k,\n",
    "                min_k=2,\n",
    "                sim_options={\n",
    "                    'name': 'pearson_baseline',\n",
    "                    'user_based': False,\n",
    "                    'min_support': 2,\n",
    "                    'shrinkage': 100\n",
    "                }\n",
    "            )\n",
    "            print(f\"KNN configurado con k={k}\")\n",
    "        else:\n",
    "            print(\"No se incluirá KNN debido a insuficientes datos o ratings por instrumento\")\n",
    "        \n",
    "        self.mejor_modelo = None\n",
    "        self.metricas_modelos = {}\n",
    "        \n",
    "        print(f\"\\nTotal de instrumentos únicos: {len(todos_instrumentos)}\")\n",
    "        print(f\"Total de ratings: {len(self.ratings_finales)}\")\n",
    "\n",
    "    def evaluar_modelos(self):\n",
    "        \"\"\"\n",
    "        Evalúa diferentes modelos usando validación cruzada\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Diccionario con las métricas de evaluación de cada modelo\n",
    "        \"\"\"\n",
    "        if len(self.ratings_finales) < 5:\n",
    "            raise ValueError(\"Se necesitan al menos 5 ratings para evaluar los modelos\")\n",
    "            \n",
    "        print(\"\\nEvaluando modelos...\")\n",
    "        for nombre, modelo in self.modelos.items():\n",
    "            try:\n",
    "                # Realizar validación cruzada\n",
    "                n_folds = min(5, len(self.ratings_finales) // 2)\n",
    "                n_folds = max(2, n_folds)\n",
    "                \n",
    "                resultados = cross_validate(\n",
    "                    modelo, \n",
    "                    self.data, \n",
    "                    measures=['RMSE', 'MAE'], \n",
    "                    cv=n_folds, \n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                self.metricas_modelos[nombre] = {\n",
    "                    'RMSE_medio': np.mean(resultados['test_rmse']),\n",
    "                    'MAE_medio': np.mean(resultados['test_mae']),\n",
    "                    'tiempo_fit_medio': np.mean(resultados['fit_time']),\n",
    "                    'tiempo_test_medio': np.mean(resultados['test_time'])\n",
    "                }\n",
    "                \n",
    "                print(f\"✓ Modelo {nombre} evaluado exitosamente\")\n",
    "                print(f\"  RMSE: {self.metricas_modelos[nombre]['RMSE_medio']:.4f}\")\n",
    "                print(f\"  MAE: {self.metricas_modelos[nombre]['MAE_medio']:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error evaluando modelo {nombre}: {str(e)}\")\n",
    "                print(\"  Este modelo será excluido de las recomendaciones\")\n",
    "                continue\n",
    "        \n",
    "        if not self.metricas_modelos:\n",
    "            raise ValueError(\"Ningún modelo pudo ser evaluado exitosamente\")\n",
    "            \n",
    "        # Encontrar el mejor modelo basado en RMSE\n",
    "        mejor_modelo_nombre = min(\n",
    "            self.metricas_modelos, \n",
    "            key=lambda x: self.metricas_modelos[x]['RMSE_medio']\n",
    "        )\n",
    "        self.mejor_modelo = self.modelos[mejor_modelo_nombre]\n",
    "        print(f\"\\n→ Mejor modelo: {mejor_modelo_nombre}\")\n",
    "        \n",
    "        return self.metricas_modelos\n",
    "\n",
    "    def evaluar_modelos(self):\n",
    "        \"\"\"\n",
    "        Evalúa diferentes modelos usando validación cruzada\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Diccionario con las métricas de evaluación de cada modelo\n",
    "        \"\"\"\n",
    "        if len(self.ratings_finales) < 5:\n",
    "            raise ValueError(\"Se necesitan al menos 5 ratings para evaluar los modelos\")\n",
    "            \n",
    "        print(\"\\nEvaluando modelos...\")\n",
    "        for nombre, modelo in self.modelos.items():\n",
    "            try:\n",
    "                # Realizar validación cruzada\n",
    "                n_folds = min(5, len(self.ratings_finales) // 2)\n",
    "                n_folds = max(2, n_folds)\n",
    "                \n",
    "                resultados = cross_validate(\n",
    "                    modelo, \n",
    "                    self.data, \n",
    "                    measures=['RMSE', 'MAE'], \n",
    "                    cv=n_folds, \n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                self.metricas_modelos[nombre] = {\n",
    "                    'RMSE_medio': np.mean(resultados['test_rmse']),\n",
    "                    'MAE_medio': np.mean(resultados['test_mae']),\n",
    "                    'tiempo_fit_medio': np.mean(resultados['fit_time']),\n",
    "                    'tiempo_test_medio': np.mean(resultados['test_time'])\n",
    "                }\n",
    "                \n",
    "                print(f\"✓ Modelo {nombre} evaluado exitosamente\")\n",
    "                print(f\"  RMSE: {self.metricas_modelos[nombre]['RMSE_medio']:.4f}\")\n",
    "                print(f\"  MAE: {self.metricas_modelos[nombre]['MAE_medio']:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error evaluando modelo {nombre}: {str(e)}\")\n",
    "                print(\"  Este modelo será excluido de las recomendaciones\")\n",
    "                continue\n",
    "        \n",
    "        if not self.metricas_modelos:\n",
    "            raise ValueError(\"Ningún modelo pudo ser evaluado exitosamente\")\n",
    "            \n",
    "        # Encontrar el mejor modelo basado en RMSE\n",
    "        mejor_modelo_nombre = min(\n",
    "            self.metricas_modelos, \n",
    "            key=lambda x: self.metricas_modelos[x]['RMSE_medio']\n",
    "        )\n",
    "        self.mejor_modelo = self.modelos[mejor_modelo_nombre]\n",
    "        print(f\"\\n→ Mejor modelo: {mejor_modelo_nombre}\")\n",
    "        \n",
    "        return self.metricas_modelos\n",
    "\n",
    "    def entrenar_mejor_modelo(self):\n",
    "        \"\"\"\n",
    "        Entrena el mejor modelo con todos los datos\n",
    "        \"\"\"\n",
    "        if self.mejor_modelo is None:\n",
    "            raise ValueError(\"Debe evaluar los modelos primero\")\n",
    "            \n",
    "        trainset = self.data.build_full_trainset()\n",
    "        self.mejor_modelo.fit(trainset)\n",
    "\n",
    "    def generar_recomendaciones(self, instrumento_id, n=5):\n",
    "        \"\"\"\n",
    "        Genera recomendaciones para un instrumento específico con manejo de errores\n",
    "        \"\"\"\n",
    "        if self.mejor_modelo is None:\n",
    "            raise ValueError(\"Debe entrenar el modelo primero\")\n",
    "            \n",
    "        # Obtener todos los instrumentos únicos\n",
    "        instrumentos_unicos = set(self.ratings_finales['Instrumento_A'].unique()) | \\\n",
    "                            set(self.ratings_finales['Instrumento_B'].unique())\n",
    "        \n",
    "        if instrumento_id not in instrumentos_unicos:\n",
    "            raise ValueError(f\"Instrumento {instrumento_id} no encontrado en el conjunto de datos\")\n",
    "        \n",
    "        # Generar predicciones para todos los pares posibles\n",
    "        predicciones = []\n",
    "        for otro_instrumento in instrumentos_unicos:\n",
    "            if otro_instrumento != instrumento_id:\n",
    "                try:\n",
    "                    pred = self.mejor_modelo.predict(instrumento_id, otro_instrumento)\n",
    "                    predicciones.append({\n",
    "                        'Instrumento_origen': instrumento_id,\n",
    "                        'Instrumento_recomendado': otro_instrumento,\n",
    "                        'Rating_predicho': pred.est,\n",
    "                        'Detalles': pred.details\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error prediciendo para {otro_instrumento}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if not predicciones:\n",
    "            raise ValueError(\"No se pudieron generar predicciones\")\n",
    "            \n",
    "        # Convertir a DataFrame y ordenar\n",
    "        df_recomendaciones = pd.DataFrame(predicciones)\n",
    "        df_recomendaciones = df_recomendaciones.sort_values(\n",
    "            'Rating_predicho', \n",
    "            ascending=False\n",
    "        ).head(n)\n",
    "        \n",
    "        return df_recomendaciones\n",
    "\n",
    "    def mostrar_metricas(self):\n",
    "        \"\"\"\n",
    "        Muestra las métricas de evaluación de todos los modelos\n",
    "        \"\"\"\n",
    "        if not self.metricas_modelos:\n",
    "            raise ValueError(\"No hay métricas disponibles. Debe evaluar los modelos primero\")\n",
    "            \n",
    "        df_metricas = pd.DataFrame(self.metricas_modelos).round(4)\n",
    "        return df_metricas.transpose()\n",
    "\n",
    "def crear_y_evaluar_sistema(ratings_finales):\n",
    "    \"\"\"\n",
    "    Función principal para crear y evaluar el sistema de recomendación\n",
    "    \"\"\"\n",
    "    # Verificar que tenemos suficientes datos\n",
    "    if len(ratings_finales) < 5:\n",
    "        raise ValueError(\"Se necesitan al menos 5 ratings para crear el sistema\")\n",
    "        \n",
    "    # Verificar que tenemos variabilidad en los ratings\n",
    "    if ratings_finales['Rating'].std() < 0.1:\n",
    "        raise ValueError(\"No hay suficiente variabilidad en los ratings\")\n",
    "        \n",
    "    # Crear sistema\n",
    "    sistema = SistemaRecomendacion(ratings_finales)\n",
    "    \n",
    "    # Evaluar modelos\n",
    "    try:\n",
    "        metricas = sistema.evaluar_modelos()\n",
    "        print(\"\\nMétricas de evaluación:\")\n",
    "        print(sistema.mostrar_metricas())\n",
    "        \n",
    "        # Entrenar mejor modelo\n",
    "        sistema.entrenar_mejor_modelo()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la evaluación del sistema: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return sistema\n",
    "\n",
    "# Ejemplo de uso:\n",
    "\"\"\"\n",
    "try:\n",
    "    # Crear y evaluar el sistema\n",
    "    sistema = crear_y_evaluar_sistema(ratings_finales)\n",
    "    \n",
    "    # Generar recomendaciones para un instrumento específico\n",
    "    instrumento_ejemplo = ratings_finales['Instrumento_A'].iloc[126]\n",
    "    recomendaciones = sistema.generar_recomendaciones(instrumento_ejemplo, n=20)\n",
    "    print(\"\\nRecomendaciones para instrumento\", instrumento_ejemplo)\n",
    "    print(recomendaciones)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número mínimo de ratings por instrumento: 298\n",
      "Número máximo de ratings por instrumento: 804\n",
      "Promedio de ratings por instrumento: 586.13\n",
      "KNN configurado con k=20\n",
      "\n",
      "Total de instrumentos únicos: 412\n",
      "Total de ratings: 120742\n",
      "\n",
      "Evaluando modelos...\n",
      "✓ Modelo SVD evaluado exitosamente\n",
      "  RMSE: 0.2099\n",
      "  MAE: 0.1222\n",
      "✓ Modelo NMF evaluado exitosamente\n",
      "  RMSE: 0.3565\n",
      "  MAE: 0.2321\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "✓ Modelo KNN evaluado exitosamente\n",
      "  RMSE: 0.2610\n",
      "  MAE: 0.1435\n",
      "\n",
      "→ Mejor modelo: SVD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SVD': {'RMSE_medio': 0.20991074633778362,\n",
       "  'MAE_medio': 0.12221521253009289,\n",
       "  'tiempo_fit_medio': 0.4337204933166504,\n",
       "  'tiempo_test_medio': 0.07608060836791992},\n",
       " 'NMF': {'RMSE_medio': 0.356488879812866,\n",
       "  'MAE_medio': 0.23212276619549055,\n",
       "  'tiempo_fit_medio': 0.8814755439758301,\n",
       "  'tiempo_test_medio': 0.08737149238586425},\n",
       " 'KNN': {'RMSE_medio': 0.2609552382475045,\n",
       "  'MAE_medio': 0.14347850728380682,\n",
       "  'tiempo_fit_medio': 1.0844550132751465,\n",
       "  'tiempo_test_medio': 2.0849525928497314}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear y entrenar el sistema de recomendación\n",
    "sistema = SistemaRecomendacion(ratings_finales)\n",
    "\n",
    "#sistema.evaluar_modelos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sistema.entrenar_mejor_modelo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting fastapi<1.0 (from gradio)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.10-cp39-none-win_amd64.whl.metadata (51 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.7.1-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.3.0->gradio)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1.0->gradio)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.20.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.23.4-cp39-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\supegui\\appdata\\local\\anaconda3\\envs\\surprise_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 6.3/18.1 MB 32.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.9/18.1 MB 37.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 36.7 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Downloading orjson-3.10.10-cp39-none-win_amd64.whl (139 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp39-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 21.3 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Downloading ruff-0.7.1-py3-none-win_amd64.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.9/9.4 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.8/9.4 MB 13.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.4 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Downloading websockets-12.0-cp39-cp39-win_amd64.whl (124 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: pydub, websockets, tqdm, tomlkit, sniffio, shellingham, semantic-version, ruff, pyyaml, python-multipart, pydantic-core, orjson, markupsafe, h11, fsspec, filelock, ffmpy, annotated-types, aiofiles, uvicorn, pydantic, huggingface-hub, httpcore, anyio, typer, starlette, httpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.6.2.post1 fastapi-0.115.4 ffmpy-0.4.0 filelock-3.16.1 fsspec-2024.10.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.2 markupsafe-2.1.5 orjson-3.10.10 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.17 pyyaml-6.0.2 ruff-0.7.1 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.41.2 tomlkit-0.12.0 tqdm-4.66.6 typer-0.12.5 uvicorn-0.32.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "# Asegúrate de que `SistemaRecomendacion` y `data_arco` ya estén definidos\n",
    "# Supón que `sistema` ya está creado y entrenado\n",
    "\n",
    "# Convertir el DataFrame `data_arco` en un diccionario para una consulta rápida\n",
    "descripcion_instrumentos = data_arco.set_index(\"Nombre del Instrumento\")[\"Descripcion\"].to_dict()\n",
    "\n",
    "# Función para obtener recomendaciones y sus descripciones\n",
    "def obtener_recomendaciones(instrumento_id):\n",
    "    # Generar recomendaciones con el sistema de recomendación\n",
    "    recomendaciones_df = sistema.generar_recomendaciones(instrumento_id, n=5)\n",
    "    recomendaciones = recomendaciones_df[\"Instrumento_recomendado\"].tolist()\n",
    "    \n",
    "    # Obtener las descripciones para cada instrumento recomendado\n",
    "    descripciones = {inst: descripcion_instrumentos.get(inst, \"Descripción no disponible\") for inst in recomendaciones}\n",
    "    \n",
    "    return recomendaciones\n",
    "\n",
    "# Función para mostrar la descripción de un instrumento específico\n",
    "def mostrar_descripcion(instrumento):\n",
    "    if isinstance(instrumento, list):  # Verificar que es una lista y tomar el primer elemento\n",
    "        instrumento = instrumento[0] if instrumento else None\n",
    "    return descripcion_instrumentos.get(instrumento, \"Descripción no disponible\") if instrumento else \"Descripción no disponible\"\n",
    "\n",
    "# Crear interfaz Gradio\n",
    "with gr.Blocks() as interfaz:\n",
    "    gr.Markdown(\"# Sistema de Recomendación de Instrumentos de Política\")\n",
    "    \n",
    "    # Selección del instrumento principal\n",
    "    instrumento_elegido = gr.Dropdown(label=\"Selecciona un instrumento\",\n",
    "                                      choices=list(sistema.ratings_finales[\"Instrumento_A\"].unique()))\n",
    "    \n",
    "    # Sección de recomendaciones\n",
    "    lista_recomendaciones = gr.Dropdown(label=\"Instrumentos recomendados\")\n",
    "    descripcion_recomendada = gr.Textbox(label=\"Descripción del instrumento seleccionado\")\n",
    "    \n",
    "    # Función para actualizar lista de recomendaciones al seleccionar un instrumento\n",
    "    def actualizar_recomendaciones(instrumento):\n",
    "        recomendaciones = obtener_recomendaciones(instrumento)\n",
    "        return gr.update(choices=recomendaciones)\n",
    "\n",
    "    # Llamada para actualizar la lista de recomendaciones\n",
    "    instrumento_elegido.change(fn=actualizar_recomendaciones, inputs=[instrumento_elegido], outputs=[lista_recomendaciones])\n",
    "\n",
    "    # Actualización de la descripción\n",
    "    lista_recomendaciones.change(fn=mostrar_descripcion, inputs=[lista_recomendaciones], outputs=[descripcion_recomendada])\n",
    "\n",
    "# Inicia la interfaz\n",
    "if __name__ == \"__main__\":\n",
    "    interfaz.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
